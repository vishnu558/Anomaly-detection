# -*- coding: utf-8 -*-
"""LogiScope_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yn4Y_dNWDmOuTbSYIo9dYg7IdN-UIsJh

#Importing the necessary Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler

"""# Loading the data"""

data=pd.read_csv("/content/sensor.csv")
data

"""# Data Preprocessing according to our work requirements

"""

data.info()

# as our work is related with the time stamp and the any one sensor we are going to choose the sensor_27 which is the best for the next steps as
# it contains the less non-null values than the other sensor data available according to the above info

data['timestamp'] = pd.to_datetime(data['timestamp'])
# Ensuring that is everything in order or not
data = data.sort_values('timestamp')
df = pd.DataFrame({'time-stamp': data['timestamp'], 'sensor': data['sensor_27'].interpolate(method='linear')})
df = df.reset_index(drop=True)
df.head()

# Ensuring the data have atleast the 5000 data points
df.shape

plt.figure(figsize=(15,4))
plt.plot(df['time-stamp'], df['sensor'])
plt.title('Sensor 27 Values Over Time')
plt.xlabel('Time')
plt.ylabel('Sensor 27')
plt.grid(True)
plt.show()

"""# visualization for better understanding

"""

scaler = StandardScaler()
df['scaled'] = scaler.fit_transform(df[['sensor']])
df.head()

"""# Isolation *Forest*"""

from sklearn.ensemble import IsolationForest

iso = IsolationForest(contamination=0.01, random_state=42)
df['iso_anomaly'] = iso.fit_predict(df[['scaled']])
df['iso_anomaly'] = df['iso_anomaly'].map({1: 0, -1: 1})
df.head()

# let's see the total anomolies using the Isolation Forest technique
df.iso_anomaly.value_counts()

"""# Isolation Forest Visualization"""

plt.figure(figsize=(15, 4))
plt.plot(df['time-stamp'], df['sensor'], label='Sensor Data', color='blue', alpha=0.6)
plt.scatter(df[df['iso_anomaly'] == 1]['time-stamp'], df[df['iso_anomaly'] == 1]['sensor'], color='red', label='Isolation Forest Anomalies', s=20)
plt.title('Sensor Data with Isolation Forest Anomalies')
plt.xlabel('Time')
plt.ylabel('Sensor Value')
plt.legend()
plt.grid(True)
plt.show()

df['time_group'] = df['time-stamp'].dt.floor('H')
iso_summary = df.groupby('time_group')['iso_anomaly'].sum()
iso_summary = iso_summary[iso_summary > 0]
iso_summary = iso_summary.sort_index()

# Plot only meaningful bars
plt.figure(figsize=(16, 5))
bars = plt.bar(iso_summary.index.astype(str), iso_summary.values, color='crimson', width=0.6)
plt.title('Isolation Forest: Anomalies Over Time (Only Non-Zero Bins)')
plt.xlabel('Time')
plt.ylabel('Anomaly Count')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='-', alpha=0.7)
plt.tight_layout()
plt.show()

df.head()

"""# Local Outlier Factor"""

from sklearn.neighbors import LocalOutlierFactor
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)
df['lof_anomaly'] = lof.fit_predict(df[['scaled']])
df['lof_anomaly'] = df['lof_anomaly'].map({1: 0, -1: 1})
df.head()

# let's see the total anomolies using the local outlier factor technique
df.lof_anomaly.value_counts()

"""# Local Outlier Factor Visualization"""

plt.figure(figsize=(15, 4))
plt.plot(df['time-stamp'], df['sensor'], label='Sensor Data', color='blue', alpha=0.6)
plt.scatter(df[df['lof_anomaly'] == 1]['time-stamp'], df[df['lof_anomaly'] == 1]['sensor'], color='orange', label='LOF Anomalies', s=20)
plt.title('Sensor Data with Local Outlier Factor (LOF) Anomalies')
plt.xlabel('Time')
plt.ylabel('Sensor Value')
plt.legend()
plt.grid(True)
plt.show()

lof_summary = df.groupby('time_group')['lof_anomaly'].sum()
lof_summary = lof_summary.sort_index()



plt.figure(figsize=(16, 5))
bars = plt.bar(lof_summary.index.astype(str), lof_summary.values, color='orange')
plt.title('Local Outlier Factor: Anomalies Over Time')
plt.xlabel('Time')
plt.ylabel('Anomaly Count')
every_nth = max(1, len(lof_summary) // 20)
plt.xticks(ticks=range(len(lof_summary.index)),
           labels=lof_summary.index.astype(str),
           rotation=45, ha='right')
for idx, label in enumerate(plt.gca().get_xticklabels()):
    if idx % every_nth != 0:
        label.set_visible(False)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""# One class SVM"""

from sklearn.svm import OneClassSVM

svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.01)
df['svm_anomaly'] = svm.fit_predict(df[['scaled']])
df['svm_anomaly'] = df['svm_anomaly'].map({1: 0, -1: 1})
df.head()

# let's see the total anomolies using the local outlier factor technique
df.svm_anomaly.value_counts()

"""# One class SVM Visualization"""

plt.figure(figsize=(15, 4))
plt.plot(df['time-stamp'], df['sensor'], label='Sensor Data', color='blue', alpha=0.6)
plt.scatter(df[df['svm_anomaly'] == 1]['time-stamp'], df[df['svm_anomaly'] == 1]['sensor'], color='red', label='SVM Anomalies', s=20)
plt.title('Sensor Data with One-Class SVM Anomalies')
plt.xlabel('Time')
plt.ylabel('Sensor Value')
plt.legend()
plt.grid(True)
plt.show()

svm_summary = df.groupby('time_group')['svm_anomaly'].sum()
#svm_summary = svm_summary[svm_summary > 0].sort_index()

plt.figure(figsize=(16, 5))
plt.bar(svm_summary.index.astype(str), svm_summary.values, color='seagreen')
plt.title('One-Class SVM: Anomalies Over Time')
plt.xlabel('Time')
plt.ylabel('Anomaly Count')

every_nth = max(1, len(lof_summary) // 20)
plt.xticks(ticks=range(len(lof_summary.index)),
           labels=lof_summary.index.astype(str),
           rotation=45, ha='right')
for idx, label in enumerate(plt.gca().get_xticklabels()):
    if idx % every_nth != 0:
        label.set_visible(False)

plt.grid(axis='y', linestyle='-', alpha=0.7)
plt.tight_layout()
plt.show()





